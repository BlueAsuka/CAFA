{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import random\n",
    "import sys\n",
    "import asyncio\n",
    "import pickle\n",
    "import datetime\n",
    "import gurobipy as gp\n",
    "sys.path.append('../')\n",
    "\n",
    "from openai import OpenAI, AsyncClient\n",
    "from json import JSONDecodeError\n",
    "from tqdm.auto import tqdm\n",
    "from utils import *\n",
    "from pydantic import BaseModel\n",
    "from colorama import Fore, Style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = json.load(open('../configs./configs.json', 'r'))\n",
    "client = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "asyncclient = AsyncClient(api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "\n",
    "dt = datetime.datetime.today().strftime('%Y-%m-%d-%H-%M-%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-09-17 15:08:04.869\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mutils\u001b[0m:\u001b[36mread_txt_file\u001b[0m:\u001b[36m14\u001b[0m - \u001b[34m\u001b[1mReading file: ../data\\NL4OPT\\nl4opt.txt\u001b[0m\n",
      "\u001b[32m2024-09-17 15:08:04.870\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mutils\u001b[0m:\u001b[36mread_txt_file\u001b[0m:\u001b[36m16\u001b[0m - \u001b[34m\u001b[1mFile read successfully: ../data\\NL4OPT\\nl4opt.txt\u001b[0m\n",
      "\u001b[32m2024-09-17 15:08:04.871\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils\u001b[0m:\u001b[36mget_nl4opt_qas\u001b[0m:\u001b[36m35\u001b[0m - \u001b[1mNumber of questions: 245\u001b[0m\n",
      "\u001b[32m2024-09-17 15:08:04.871\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils\u001b[0m:\u001b[36mget_nl4opt_qas\u001b[0m:\u001b[36m36\u001b[0m - \u001b[1mNumber of answers: 245\u001b[0m\n",
      "\u001b[32m2024-09-17 15:08:04.872\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils\u001b[0m:\u001b[36mget_demo_and_test_samples\u001b[0m:\u001b[36m47\u001b[0m - \u001b[1mNumber of demo samples: 20\u001b[0m\n",
      "\u001b[32m2024-09-17 15:08:04.872\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils\u001b[0m:\u001b[36mget_demo_and_test_samples\u001b[0m:\u001b[36m48\u001b[0m - \u001b[1mNumber of test samples: 225\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = '../data'\n",
    "DATASET_NAME = 'NL4OPT' \n",
    "OUTPUT_DIR = '../output'  \n",
    "\n",
    "nl4opt_data = read_txt_file(os.path.join(DATA_DIR, DATASET_NAME, 'nl4opt.txt'))\n",
    "questions, answers = get_nl4opt_qas(nl4opt_data)\n",
    "assert len(questions) == len(answers)\n",
    "\n",
    "qa_pairs = list(zip(questions, answers))\n",
    "demo_samples, test_samples = get_demo_and_test_samples(qa_pairs)\n",
    "\n",
    "questions = [q for q, _ in demo_samples]\n",
    "answers = [a for _, a in demo_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Code(BaseModel):\n",
    "    reasoning: List[str]\n",
    "    code: str     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an expert in optimization problems and domain specific language generation. Your task is to convert the textual optimization text into a piece of code.\n",
      "Here are some examples that you should refer to:\n",
      "\n",
      "QUESTION:\n",
      "A car manufacturer makes two types of car oils: Oil Max and Oil Max Pro. A container of Oil Max contains 46 grams of substance A, 43 grams of substance B and 56 grams of substance C. A container of Oil Max Pro contains 13 grams of substance A, 4 grams of substance B and 45 grams of substance C. The car manufacturer has 1345 grams of substance A, 346 grams of substance B, 1643 grams of substance C. In addition, the profit per container of Oil Max is $10 and the profit per container of Oil Max Pro is $15. How many containers of each of oil should the car manufacturer make to maximize profit?\n",
      "CODE:\n",
      "x = m.addVar(name=\"Oil Max\", vtype=gp.GRB.INTEGER)\n",
      "y = m.addVar(name=\"Oil Max Pro\", vtype=gp.GRB.INTEGER)\n",
      "m.setObjective(10 * x + 15 * y, gp.GRB.MAXIMIZE)\n",
      "m.addConstr(46 * x + 13 * y <= 1345)\n",
      "m.addConstr(43 * x + 4 * y <= 346)\n",
      "m.addConstr(56 * x + 45 * y <= 1643)\n",
      "\n",
      "QUESTION:\n",
      "Ben is growing apples and pears on his orchard. He has 50 acres available on which he must grow a minimum of 5 acres of apples and a minimum of 10 acres of pears to meet demands. The profit per apple is $2 and the profit per pear is $4. He prefers to grow more pears than apples but limitations in his workforce allow him to grow at most twice the amount of pears as apples. How many of each fruit should Ben grow in order to maximize his profit? What is that profit?\n",
      "CODE:\n",
      "x = m.addVar(name=\"apples\", vtype=gp.GRB.INTEGER)\n",
      "y = m.addVar(name=\"pears\", vtype=gp.GRB.INTEGER)\n",
      "m.setObjective(2 * x + 4 * y, gp.GRB.MAXIMIZE)\n",
      "m.addConstr(x + y <= 50)\n",
      "m.addConstr(x >= 5)\n",
      "m.addConstr(y >= 10)\n",
      "m.addConstr(y <= 2 * x)\n",
      "\n",
      "Please finish the task think step by step.\n"
     ]
    }
   ],
   "source": [
    "sys_prompt = \"\"\"You are an expert in optimization problems and domain specific language generation. Your task is to convert the textual optimization text into a piece of code.\n",
    "Here are some examples that you should refer to:\\n\"\"\"\n",
    "\n",
    "example = \"\"\"\n",
    "QUESTION:\n",
    "A car manufacturer makes two types of car oils: Oil Max and Oil Max Pro. A container of Oil Max contains 46 grams of substance A, 43 grams of substance B and 56 grams of substance C. A container of Oil Max Pro contains 13 grams of substance A, 4 grams of substance B and 45 grams of substance C. The car manufacturer has 1345 grams of substance A, 346 grams of substance B, 1643 grams of substance C. In addition, the profit per container of Oil Max is $10 and the profit per container of Oil Max Pro is $15. How many containers of each of oil should the car manufacturer make to maximize profit?\n",
    "CODE:\n",
    "x = m.addVar(name=\"Oil Max\", vtype=gp.GRB.INTEGER)\n",
    "y = m.addVar(name=\"Oil Max Pro\", vtype=gp.GRB.INTEGER)\n",
    "m.setObjective(10 * x + 15 * y, gp.GRB.MAXIMIZE)\n",
    "m.addConstr(46 * x + 13 * y <= 1345)\n",
    "m.addConstr(43 * x + 4 * y <= 346)\n",
    "m.addConstr(56 * x + 45 * y <= 1643)\n",
    "\n",
    "QUESTION:\n",
    "Ben is growing apples and pears on his orchard. He has 50 acres available on which he must grow a minimum of 5 acres of apples and a minimum of 10 acres of pears to meet demands. The profit per apple is $2 and the profit per pear is $4. He prefers to grow more pears than apples but limitations in his workforce allow him to grow at most twice the amount of pears as apples. How many of each fruit should Ben grow in order to maximize his profit? What is that profit?\n",
    "CODE:\n",
    "x = m.addVar(name=\"apples\", vtype=gp.GRB.INTEGER)\n",
    "y = m.addVar(name=\"pears\", vtype=gp.GRB.INTEGER)\n",
    "m.setObjective(2 * x + 4 * y, gp.GRB.MAXIMIZE)\n",
    "m.addConstr(x + y <= 50)\n",
    "m.addConstr(x >= 5)\n",
    "m.addConstr(y >= 10)\n",
    "m.addConstr(y <= 2 * x)\n",
    "\"\"\"\n",
    "\n",
    "sys_prompt = sys_prompt + example + \"\\nPlease finish the task think step by step.\"\n",
    "print(sys_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:21<00:00,  7.07s/it]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 8\n",
    "lp_reasoning_list = []\n",
    "for idx in tqdm(range(0, len(questions), batch_size)):\n",
    "    batch = questions[idx:idx+batch_size]\n",
    "    \n",
    "    tasks = [asyncclient.beta.chat.completions.parse(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        temperature=0,\n",
    "        response_format=Code,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": sys_prompt},\n",
    "            {\"role\": \"user\", \"content\": f\"QUESTION: {q}\"}\n",
    "        ]) for q in batch\n",
    "    ]\n",
    "\n",
    "    combined_responses = await asyncio.gather(*tasks)\n",
    "    lp_reasoning_list.extend([r.choices[0].message.parsed for r in combined_responses])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'e2e_codegen_small_gurobi_' + dt + '.pkl'\n",
    "with open(os.path.join(OUTPUT_DIR, filename), 'wb') as f:\n",
    "    pickle.dump(lp_reasoning_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = [lp_reasoning_list[i].code for i in range(len(lp_reasoning_list))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"\"\"\n",
    "import gurobipy as gp\n",
    "env = gp.Env(empty=True)\n",
    "env.setParam(\"OutputFlag\",0)\n",
    "env.start()\n",
    "m = gp.Model(env=env)\n",
    "\"\"\"\n",
    "                \n",
    "suffix = \"\"\"\n",
    "m.optimize()\n",
    "\"\"\"\n",
    "\n",
    "def complement_code(code: str) -> float:\n",
    "    return prefix + code + suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_code(code: str) -> str:\n",
    "    cleand_code = []\n",
    "    for line in code.split('\\n'):\n",
    "        line = line.strip()\n",
    "        if line.startswith('m.addConstr') and not re.findall(r'<=|>=', line):\n",
    "            line = re.sub(r'<', r'<=', line)\n",
    "            line = re.sub(r'>', r'>=', line)\n",
    "        cleand_code.append(line)\n",
    "    return '\\n'.join(cleand_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_code(code: str) -> float:\n",
    "    ex_locals = {}\n",
    "    exec(code, None, ex_locals)\n",
    "    \n",
    "    try:\n",
    "        return ex_locals[\"m\"].objVal\n",
    "    except Exception as e:\n",
    "        # print(e)\n",
    "        return np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-09-17 15:47:34.965\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m7\u001b[0m - \u001b[1mquestion 0 obtain answer\u001b[0m\n",
      "\u001b[32m2024-09-17 15:47:34.968\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m7\u001b[0m - \u001b[1mquestion 1 obtain answer\u001b[0m\n",
      "\u001b[32m2024-09-17 15:47:34.971\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m7\u001b[0m - \u001b[1mquestion 2 obtain answer\u001b[0m\n",
      "\u001b[32m2024-09-17 15:47:34.973\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m7\u001b[0m - \u001b[1mquestion 3 obtain answer\u001b[0m\n",
      "\u001b[32m2024-09-17 15:47:34.975\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m7\u001b[0m - \u001b[1mquestion 4 obtain answer\u001b[0m\n",
      "\u001b[32m2024-09-17 15:47:34.976\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m7\u001b[0m - \u001b[1mquestion 5 obtain answer\u001b[0m\n",
      "\u001b[32m2024-09-17 15:47:34.978\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m7\u001b[0m - \u001b[1mquestion 6 obtain answer\u001b[0m\n",
      "\u001b[32m2024-09-17 15:47:34.980\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m7\u001b[0m - \u001b[1mquestion 7 obtain answer\u001b[0m\n",
      "\u001b[32m2024-09-17 15:47:34.981\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m7\u001b[0m - \u001b[1mquestion 8 obtain answer\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-09-17 15:47:34.983\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m7\u001b[0m - \u001b[1mquestion 9 obtain answer\u001b[0m\n",
      "\u001b[32m2024-09-17 15:47:34.984\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m7\u001b[0m - \u001b[1mquestion 10 obtain answer\u001b[0m\n",
      "\u001b[32m2024-09-17 15:47:34.985\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m7\u001b[0m - \u001b[1mquestion 11 obtain answer\u001b[0m\n",
      "\u001b[32m2024-09-17 15:47:34.987\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m7\u001b[0m - \u001b[1mquestion 12 obtain answer\u001b[0m\n",
      "\u001b[32m2024-09-17 15:47:34.988\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m7\u001b[0m - \u001b[1mquestion 13 obtain answer\u001b[0m\n",
      "\u001b[32m2024-09-17 15:47:34.989\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m7\u001b[0m - \u001b[1mquestion 14 obtain answer\u001b[0m\n",
      "\u001b[32m2024-09-17 15:47:34.991\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m7\u001b[0m - \u001b[1mquestion 15 obtain answer\u001b[0m\n",
      "\u001b[32m2024-09-17 15:47:34.993\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m7\u001b[0m - \u001b[1mquestion 16 obtain answer\u001b[0m\n",
      "\u001b[32m2024-09-17 15:47:34.995\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m7\u001b[0m - \u001b[1mquestion 17 obtain answer\u001b[0m\n",
      "\u001b[32m2024-09-17 15:47:34.997\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m7\u001b[0m - \u001b[1mquestion 18 obtain answer\u001b[0m\n",
      "\u001b[32m2024-09-17 15:47:34.999\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m7\u001b[0m - \u001b[1mquestion 19 obtain answer\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "pred_answers = []\n",
    "for i, code_str in enumerate(codes):\n",
    "    try:\n",
    "        cleaned_code = clean_code(code_str)\n",
    "        code = complement_code(cleaned_code)\n",
    "        ans = execute_code(code)\n",
    "        loguru.logger.info(f\"question {i} obtain answer\")\n",
    "        pred_answers.append(ans)\n",
    "    except Exception as e:\n",
    "        loguru.logger.error(f\"Error for question {i}: {e}\")\n",
    "        pred_answers.append(\"Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[540.0, 166.0, 950.0, 37083.3333, 342750.0, 7000.0, 100.0, 11980.0, 480.0, 142.0, 465.0, inf, 67.0, inf, 1500.0, 511.4286, 1060.0, 11275.0, 20.0, 50.0]\n"
     ]
    }
   ],
   "source": [
    "print([round(pa, 4) for pa in pred_answers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['540.0', '166.66666666666669', '950.0', '36900.0', '342750.0', '7000.0', '100.0', '11980.0', '480.0', '142.0', '465.0', inf, '67.0', inf, '1500.0', '511.42857142857133', '1060.0', '2500.0', '20.0', '-99999']\n"
     ]
    }
   ],
   "source": [
    "print(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = []\n",
    "for p, r in zip(pred_answers, answers):\n",
    "    if p == 'Error':\n",
    "        continue\n",
    "    if (float(p) == np.inf and float(r) == np.inf) or (abs(float(p) - float(r)) / float(r) < 1e-2):\n",
    "        correct.append(True)\n",
    "    else:\n",
    "        correct.append(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95.0"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sum(correct) / len(answers)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "or",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
